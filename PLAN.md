# Plan
| Day                                           | Key Outcome                                                 | Concrete Tasks & Resources                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| --------------------------------------------- | ----------------------------------------------------------- |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **1. Know OpusClip inside-out**               | • Clear picture of the product, users & market.             | 1. **Read & Watch**  <br>• YC interview (YouTube) with CEO Young Zhao (12 min) <br>• [Business Insider article](https://techfundingnews.com/opusclip-grabs-20m-for-ai-powered-video-editing-tool-that-turns-long-content-into-short-viral-clips/) (May 2024) – funding & roadmap <br>• Case-study page: “How MrBeast’s shorts were auto-generated” <br><br>2. **Hands-on**  <br>• Sign up for the free plan → upload one of your own long-form videos, step through clip generation, note every screen, latency, clip metrics, hashtags, etc.  <br>• Capture user-flows in Miro / Notion (pain points, delights).                                                                                                                                                                                                                                                                                                                                                                                                                    |
| **2. Deep dive: Tech stack & tooling**        | Understand the building blocks you’ll use on the prototype. | **Video ingestion / metadata**  <br>• `yt-dlp` or `pytube` – download & basic metadata. <br>• YouTube Data API v3 – channel & caption endpoints. <br><br>**Transcription / diarization**  <br>• OpenAI Whisper, Google Speech-to-Text, or AssemblyAI. <br><br>**Editing & rendering**  <br>• `ffmpeg` CLI, `moviepy` (Python), `Remotion` (React). <br><br>**LLMs & RAG**  <br>• LangChain, LlamaIndex, or VertexAI’s Gen-App-Builder. <br><br>**Agents / orchestration**  <br>• LangChain Agents (ReAct, Function-Calling), CrewAI. <br>• `langgraph` for multi-step chains. <br><br>**Multi-modal evaluators**  <br>• OpenAI GPT-4o vision, Google Gemini 1.5, or open-source CLIP/LLaVA for frame-text similarity. <br><br>**Infra**  <br>• GCP Cloud Run, Cloud Functions (Python/Node) <br>• Cloud SQL (PostgreSQL) & Memorystore (Redis) <br>• Cloudflare Workers for low-latency edge serving |
| **3. Primer: RAG, Agents & multi-modal eval** | Comfort with concepts you’ve never shipped before.          | 1. ★ Read: “RAG explained” (Harrison Chase), “How to evaluate RAG” (Arize). <br>2. Code-along: <br>`python<br>from llama_index import SimpleDirectoryReader, VectorStoreIndex, SummaryRetriever<br>docs = SimpleDirectoryReader('docs').load_data()<br>index = VectorStoreIndex.from_documents(docs)<br>print(index.query('Who is the target user?'))<br>`<br>3. Build a **tiny agent** that answers a question, then *evaluates its own answer* with GPT-4 (self-critique).                                                                                                                                                                                                                                                                                                                                                                                                                         |
| **4. Scaffold the prototype**                 | Full-stack skeleton running.                                | 1. **Repo**: Turborepo / monorepo with:  <br>• `apps/web` – Next.js  (React 18, TypeScript, SSR). <br>• `apps/api` – Fastify + Nest.js or Express wrapped by `ts-node` (up-front parity with their stack). <br>• `packages/core` – shared utils (YouTube fetch, transcript). <br><br>2. **Auth & UI**: next-auth + Chakra/Tailwind. <br>3. **CI/CD**: GitHub Actions → Vercel Preview + Cloud Run deploy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| **5. MVP: “URL → Highlight Clips”**           | End-to-end demo works on a short video.                     | Workflow: 1) User pastes YT URL. 2) Server downloads & transcribes. 3) LLM summarizer returns top N moments (use scoring: speaker excitement, chat-GPT keywords, subtitle density). 4) Cut with ffmpeg + `-ss` / `-to`. 5) Serve MP4s in UI gallery. <br><br>• Store transcripts + clip metadata in Postgres. <br>• Queue heavy jobs on Cloud Tasks + Pub/Sub.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| **6. Level-up with Agents & Multi-modal**     | Prototype shows AI “co-pilot” selection wins.               | 1. **Agent Planner** (LangChain Agents) that: <br>• Decides which extractor (audio vs. visual) to call. <br>• Calls CLIP to rank scenes by visual novelty. <br>• Aggregates scores (text + vision) → final top N. <br><br>2. **Evaluation loop**: Ask GPT-4o to critique each clip vs. the full transcript → store rating; display top score in UI.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| **7. Polish & Prep for interview**            | Demo, slides, talking points.                               | 1. **Bundle & perf**: Lighthouse > 90 (hook into Next.js critical CSS, code-split, Vite). <br>2. **Observability**: add Sentry & OpenTelemetry traces. <br>3. **Slides (6pp)**: Problem → Architecture → Live demo GIF → Metrics → Next steps. <br>4. **Mock interview**: pair-program a bug fix on the repo, narrate thought process, emphasize Opus core values (customer obsession, move fast, craftsmanship).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Summary of Libraries/Services
| Need                      | Library / Service                      |
| ------------------------- | -------------------------------------- |
| Video ingest & processing | `yt-dlp`, `ffmpeg`, `moviepy`          |
| Speech-to-text & language | Whisper cpp / VertexAI Speech          |
| RAG store                 | PGVector on Cloud SQL or Pinecone      |
| Embeddings & multimodal   | OpenAI Embeddings, CLIP, Gemini Vision |
| Agent framework           | LangChain Agents, CrewAI               |
| Serverless infra          | Cloud Run + Cloud Tasks (GCP)          |
| Edge delivery & SSR       | Next.js on Vercel + Cloudflare cache   |
